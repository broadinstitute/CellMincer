.. _usage:

Usage
=====

This is a walkthrough of the CellMincer pipeline using an Optosynth dataset as an example. This dataset (2.4 GB) can be `downloaded here <https://storage.cloud.google.com/bw-cellmincer-dev/Optosynth/raw/optosynth__1__20__50.tif>`_.

Declaring a dataset manifest
----------------------------

CellMincer accepts ``.tif``, ``.bin``, and ``.npy`` formats as input, so for standardization, CellMincer expects a YAML file containing the basic specifications of the data. For our example, `the manifest <https://storage.cloud.google.com/bw-cellmincer-dev/configs/manifest.yaml>`_ would look like this:

.. code-block::

    n_frames_per_segment: 1000
    n_segments: 7
    order: tyx
    sampling_rate: 500

The dataset in question contains 7000 frames split into 7 equal segments, each of which undergoes stimulation at a different intensity. The ``order`` parameter describes the dataset's order of dimensions; in this case, the data when read as a tensor is structured as ``time x height x width``, abbreviated as ``tyx``. The sampling rate is in Hz.

For ``.bin`` files, which do not directly encode shape, we would specify additional arguments for ``width`` and ``height``.

Preprocessing
-------------

Preprocessing is performed using the command ``cellmincer preprocess``. It takes as input a path to the dataset, its manifest, and a configuration YAML file. It outputs a directory containing the detrended data, precomputed global features, and other components used for training and inference.

Unlike the manifest, the preprocessing configuration does not generally need to be tailored to the data, barring certain imaging artifacts that need correction. A suitable configuration for our Optosynth data can be `found here <https://storage.cloud.google.com/bw-cellmincer-dev/configs/preprocess.yaml>`_, and more information about preprocessing options can be found in the :ref:`Reference <reference>` section.

Note that this configuration assumes the use of GPU support; if unavailable, the ``device`` config option should be changed to ``cpu``.

With our three files in our current working directory, we can generate our preprocessing output in the same location with this command:

.. code-block:: console

   (cellmincer) $ cellmincer preprocess \
                  -i optosynth__1__20__50.tif \
                  -o ./optosynth__1__20__50 \
                  --manifest manifest.yaml \
                  --config preprocess.yaml

Training
--------

.. note::
    This step will take a *much longer* time than the others. Consider skipping this step and downloading `this pretrained model <https://storage.cloud.google.com/bw-cellmincer-dev/models/optosynth.ckpt>`_.

Training is conducted using ``cellmincer train``. It takes as input one or more dataset directories (generated by preprocessing), and a configuration YAML file. It outputs a PyTorch Lightning checkpoint containing the final model state. Optionally, it can take arguments for choosing an existing model state for initialization, for resuming training from an intermediate checkpoint, and for increasing the number of GPUs. We recommend using `this configuration <https://storage.cloud.google.com/bw-cellmincer-dev/configs/train.yaml>`_ for training a first model.

We can use the following command to train on our single Optosynth dataset:

.. code-block:: console

   (cellmincer) $ cellmincer train \
                  -i ./optosynth__1__20__50 \
                  -o . \
                  --config train.yaml

After each iteration, the current model state will be logged to the current working directory as ``last.ckpt``. When our training is complete, this will be our trained model.

For consistency, let's rename our trained model to ``optosynth.ckpt``.

.. code-block:: console

   (cellmincer) $ mv last.ckpt optosynth.ckpt

Denoising
---------

With a trained model, denoising is a comparatively quick operation. Using the same generated dataset directory, we can use ``cellmincer denoise`` with a model checkpoint to denoise the data using that model. This command also requires a ``--type`` argument to look up the class associated with this model, but as of the most recent CellMincer version, this argument is fixed. Optionally, you can disable the ``.avi`` visualization with the ``--no-avi`` flag (necessary if you do not have a ffmpeg installation). Conversely, you can customize the visualization by choosing a frame range to render over or by adjusting the scaling. See the :ref:`Reference <reference>` for more details.

.. code-block:: console

   (cellmincer) $ cellmincer denoise \
                  -i ./optosynth__1__20__50 \
                  -o . \
                  --model optosynth.ckpt \
                  --type spatial-unet-2d-temporal-denoiser

This outputs two versions of the denoised data. The first is in the original scale, while the second is "detrended" and can more easily be visualized.
